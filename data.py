tag_descriptions = {
    "Behavioral Data Collection": "The company develops several algorithms to analyze the data collected from the tracker and predicts the types of metabolism activity - along with duration and intensity.",
    "High Risk Probability": "The use of digital tools and platforms to influence the outcome of elections, undermining the integrity of democratic processes.",
    "Personal Identifiable Data Collection": "The use of algorithms to assess job applicants' suitability, potentially overlooking human nuances and leading to biased outcomes.",
    "Restricted Choices": "The heightened risk of individuals or systems being susceptible to breaches through manipulative psychological tactics.",
    "Bio Data Collection": "The ability to clearly understand and communicate the rationale behind decisions made by algorithms.",
    "Self-Moderation": "Platforms where users have the ability to report and remove content that violates community standards, potentially leading to issues of content control and privacy.",
    "User-Generated Content": "Environments where users create and share content, which can lead to privacy concerns if not properly moderated or if sensitive information is shared.",
    "Virtual Identity Management": "Platforms that allow users to create and manage virtual identities, which can raise privacy concerns if these identities are linked to real-world data or if they are used inappropriately.",
    "Espionage Oversight": "Lack of sufficient oversight and regulation over espionage activities that impact the privacy rights of non-US citizens, particularly in allied nations.",
    "Data Privacy Rights": "Inadequate protection and redress mechanisms for the data privacy rights of individuals, especially those residing in countries other than the US, leading to concerns over surveillance and data collection practices.",
    "Transatlantic Privacy Dispute": "Conflicts between European and American authorities over data privacy and surveillance practices, often resulting in diplomatic tensions and negotiations.",
    "Public Exposure of Sensitive Data": "Incidents where sensitive or private information about individuals is exposed to the public through social media or other public platforms, often leading to widespread dissemination and potential harm.",
    "Unintended Data Misuse": "Situations where data collected for one purpose is misused or repurposed in a way that leads to unintended consequences, such as the public exposure of sensitive information or negative publicity.",
    "Social Media Privacy Failure": "Failures in social media campaigns or initiatives that result in the unintended exposure of private or sensitive information, often leading to public backlash and privacy concerns.",
    "Data Theft": "Incidents where personal or sensitive data is stolen by cybercriminals through various means such as phishing, malware, or man-in-the-middle attacks.",
    "Identity Theft": "Incidents where an individual's personal identification information is stolen and used without authorization, often leading to financial loss and legal action.",
    "Cybersecurity Breach": "Incidents where unauthorized individuals or groups exploit vulnerabilities in computer systems or networks to disrupt services or gain unauthorized access, potentially compromising user data and privacy.",
    "Financial Fraud": "Incidents where individuals or entities use stolen data or identities to commit financial crimes, resulting in monetary losses and privacy concerns.",
    "Digital Boundary Blurring": "The erosion of traditional boundaries between private and public spaces due to digital technologies, leading to increased exposure of personal information.",
    "Social Media Grooming": "The process by which social media platforms encourage users, particularly children, to share personal information and aspects of their lives, often without fully understanding the privacy implications.",
    "Privacy Exposure": "The increased risk of personal information being exposed or shared without consent due to the pervasive use of digital platforms and social media.",
    "Unauthorized Photography": "Incidents where individuals' privacy is invaded through unauthorized photography, particularly in private settings where they have a reasonable expectation of privacy.",
    "Press Guidelines Violation": "Situations where media organizations or photographers breach established guidelines, such as those set by the Press Complaints Commission, leading to legal consequences and damages.",
    "Celebrity Privacy": "Events involving the unauthorized intrusion into the private lives of celebrities, often by media agencies, leading to significant privacy concerns.",
    "Anonymous Testimony": "The submission of evidence by individuals under anonymity, which can lead to broad-brush accusations and reputational damage without specific identification of wrongdoing.",
    "Reputational Risk": "Situations where the anonymity of evidence submitted to inquiries or investigations can result in widespread suspicion and damage to the reputation of entire groups or industries.",
    "Media Inquiry Privacy": "Incidents related to the handling of evidence in media-focused inquiries, where the anonymity of submissions can impact the privacy and reputational concerns of media organizations and their employees.",
    "Data Sharing": "The practice of sharing personal data, such as location information, with others, including friends and acquaintances, without explicit consent beyond general app usage.",
    "Image Privacy": "The exposure of personal images and visual information online, which can be subject to unauthorized use or distribution.",
    "Social Networking Privacy": "Privacy issues arising from the use of social networking features that involve sharing personal information with friends and other users on the platform.",
    "Data Integrity Compromise": "Incidents where the integrity of data systems is compromised by unauthorized manipulation or tampering, leading to potential privacy breaches and loss of trust.",
    "Cybersecurity Threat": "Events involving cyber attacks that exploit software vulnerabilities to compromise user privacy and security, often leading to widespread concern and response.",
    "Government Data Vulnerability": "Events highlighting vulnerabilities in government data systems, where unauthorized access or manipulation could lead to significant privacy breaches and national security concerns.",
    "Government Surveillance": "State-sponsored monitoring and tracking of citizens' activities, often justified under the guise of security, but resulting in significant privacy violations.",
    "Data Privacy Breach": "Events where personal data is exposed or compromised through unauthorized access, often facilitated by spam or phishing attacks, leading to potential identity theft or other privacy violations.",
    "Whistleblower Disclosure": "Situations where an individual within an organization leaks sensitive information to the public or media, revealing practices that may violate privacy or ethical standards.",
    "Identity Disclosure": "Incidents where individuals' identities are disclosed without their consent, leading to harassment and threats.",
    "Cyber Harassment": "Online incidents involving targeted harassment, threats, and abuse directed at individuals, often escalating to real-world safety concerns.",
    "Threats and Intimidation": "Situations where individuals receive direct threats to their safety and well-being, prompting heightened security measures and legal intervention.",
    "Data Retention": "Government policies mandating the storage of personal data by service providers, often for security purposes, which can lead to privacy concerns due to potential unauthorized access.",
    "Surveillance Overreach": "The excessive and pervasive monitoring of individuals' activities through technological means, often without their consent or awareness, leading to significant privacy concerns.",
    "Biometric Data Privacy": "Concerns related to the collection, storage, and use of biometric data, such as DNA, which can have significant privacy implications.",
    "Media Privacy Violation": "Events involving media organizations that breach individuals' privacy through intrusive practices, often justified under the guise of public interest.",
    "Invasion of Privacy": "Situations where personal privacy is violated by unauthorized access or disclosure of private information or images, leading to legal consequences.",
    "Legal Intimidation": "Incidents where entities use legal tactics to intimidate individuals, discouraging them from pursuing legal remedies for privacy violations.",
    "Data Retention Mandate": "Government policies requiring organizations to retain and store personal data of users for extended periods, often for law enforcement purposes.",
    "Public Data Access": "Situations where multiple public bodies, including local councils and health authorities, are granted access to personal data for various investigative purposes, raising concerns about data privacy and misuse.",
    "EU Directive Compliance": "Incidents involving the implementation of European Union directives that require member states to adopt specific data retention and access policies, impacting privacy rights and data protection.",
    "Surveillance Expansion": "Increases in the scope and scale of government surveillance programs, capturing more detailed and extensive personal data.",
    "Right to Be Forgotten": "The legal principle that allows individuals to request the removal of personal information from online platforms to protect their privacy, especially when the information is outdated or irrelevant.",
    "Data Protection Reform": "Updates to legal frameworks that aim to better protect personal data and privacy in the digital age, addressing outdated regulations.",
     "Tech-Enabled Election Interference": "The use of digital tools and platforms to influence the outcome of elections, undermining the integrity of democratic processes.",
"Automated Employment Screening": "The use of algorithms to assess job applicants' suitability, potentially overlooking human nuances and leading to biased outcomes.",
"Social Engineering Exposure Risk": "The heightened risk of individuals or systems being susceptible to breaches through manipulative psychological tactics.",
"Algorithmic Transparency Achieved": "The ability to clearly understand and communicate the rationale behind decisions made by algorithms.",
"Lack of Algorithmic Transparency": "The difficulty in grasping and explaining the reasoning behind algorithmic decisions.",
"Algorithmic Decision-Making Utilization": "The strategic application of algorithms to process data and make informed decisions, enhancing efficiency and accuracy.",
"Algorithmic Scoring": "The apprehension surrounding the use of algorithms to assign scores to individuals, potentially affecting their opportunities and services based on automated assessments.",
"Cross-Border Data Flow": "The transfer of personal data across national borders, raising issues of privacy, jurisdiction, and compliance.",
"Data Localization Violations": "Non-compliance with regulations requiring data to be stored within the country of origin, raising legal and privacy issues.",
"User-Profitable": "Enhancing user benefits through actions and policies designed to prioritize and improve their well-being and satisfaction.",
    "Data Autonomy and Consent": "Empowering individuals with the authority to manage their own data, emphasizing voluntary engagement and the pivotal role of consent in data utilization.",
    "Low-Sensitivity Data Collection": "Confidence in data handling processes facilitated by the low sensitivity of collected data, ensuring minimal risk exposure.",
    "Data Transparency Assurance": "Ensure users have a clear understanding and reassurance regarding data handling.",
    "User Interface Dark Patterns": "Design tactics used to manipulate users into making unintended decisions, often compromising privacy or consent.",
    "Company Profitable": "Businesses gain financial advantage by analyzing and utilizing personal and behavioral data, leading to enhanced targeted marketing and personalized services.",
    "Data Anonymization Utilization": "The practice of concealing personal details within data sets to prevent identification, ensuring privacy while allowing the data to be used for analysis and decision-making.",
    "Differential Privacy Utilization": "Using mathematical techniques to analyze and share information about patterns in data without revealing specific details about individuals, ensuring privacy and security.",
    "Unclear Data Management": "Insufficient disclosure regarding the nature of data collection or its utilization. Absence of clear elucidation may lead to uncertainty.",
    "Data Minimization Neglect": "Ignoring the principle of collecting the minimum necessary data, leading to excessive data acquisition and privacy risks.",
    "Consent Complexity": "The use of convoluted or unclear consent mechanisms that confuse users or obscure the extent of data collection.",
    "Consent Withdrawal Difficulty": "Obstacles and complexities faced by users trying to revoke consent for data processing, undermining data control.",
    "IOT Data Collection": "Gathering data from interconnected devices, which may exceed necessary bounds, compromising security and privacy.",
    "Passive Data Collection": "Gathering data from users without active engagement or explicit consent, often through background tracking technologies.",
    "Location Data Collection": "The collection and use of geographical information from devices, raising issues of surveillance and personal freedom.",
    "Financial Data Collection": "Users disclose their financial information encompassing assets, liabilities, and transactional history.",
    "Location Tracking Overreach": "Initiates at collection with excessive tracking.",
    "Emotional Manipulation": "Exploitation of psychological techniques to influence emotions for specific outcomes.",
    "Behavioral Manipulation": "Utilization of psychological strategies to direct or change behaviors towards predetermined objectives.",
    "Echo Chamber Effect": "The amplification of similar viewpoints online due to algorithmic content filtering, reducing exposure to diverse perspectives.",
    "Cross-Platform Data Aggregation": "Combining user data from multiple sources to create comprehensive profiles without user consent.",
    "Psychographic Profiling": "Analysis and use of individuals' psychological traits to influence their behavior (e.g., voting, purchasing).",
    "Profiling and Personalization Risks": "The creation of detailed profiles of individuals for targeted advertising or content personalization, which may lead to privacy invasions or discrimination.",
    "Encryption Weakening": "Deliberate or negligent weakening of encryption standards, making data more susceptible to breaches.",
    "Lack of Oversight": "Insufficient mechanisms for monitoring and regulating the access and usage of retained metadata by government agencies, leading to concerns about unchecked surveillance practices and potential abuses of power.",
    "Absence of Consent": "Lack of transparency or consent, or violation of existing consent",
    "Algorithmic Assessment Imperfections": "Imperfect implementation or adoption of algorithm for assessing personal data",
    "Automated Data-Driven": "Loss of initiative due to data-driven automation",
    "Behavioral Data Collection": "Users divulge their behavioral data in the scene, which include metadata (e.g. browse history, message history), activity records (e.g. purchase record) and so on",
    "Bio Data Collection": "Users divulge their physiology data related to medical, health, or intimacy information",
    "Data Breach": "Inadequate data protection measures or unexpected data sharing",
    "Data Control Loss": "Loss of control over personal data",
    "Empathy for the Vulnerable": "Potential harm for vulnerable populations",
    "Financial Loss": "Monetary harm or economic damage",
    "High Risk Probability": "The risk is very likely to happen",
    "High Risk Significance": "The outcome is severe",
    "Opportunity Loss": "Loss of potential opportunities (e.g. promotion, competitive advantage, etc.)",
    "Personal Identifiable Data Collection": "Users divulge their personal identifiable information (PII) in the scene (e.g. e-mail address, ID information, etc.)",
    "Price Discrimination": "Charging of different prices for the same or similar products or services to different groups of consumers",
    "Reputation Loss": "Deterioration of an individual's or an organization's standing or credibility in the eyes of others",
    "Restricted Choices": "Lack of an alternative choice, and no opt-out",
    "Third Party Transfer": "Data is transferred to third parties",
    "Unexpected Use": "Violation of social norms or of expected results"}


data_practice =[" \nWhen a user made purchases at a retail store (online\/offline), the retailing company collected various behavior data, such as the purchase items, payment credit card, email address, delivery address, etc.  \n"," \nBased on the email, delivery address, credit card number, and so on, the company associates the purchase history with anonymized identity. The retail company later develops various models to predict user traits using the purchase history. For example, pregnant women purchase different items such as supplements like calcium, magnesium, and zinc. So the model guesses the customer may be pregnant if she buys these products in a short period. "," \nOnce the retail company predicts the customers might be pregnant, the company will send out tailored coupons to these parents-to-be, e.g., special coupons for diapers, baby clothes catalogs. \\n\\nSending coupons for baby items doesnt bring too much profit. The underlying goal is that the company want to re-shape their shopping habits. Research shows that first-time parents are experiencing the most hectic time in their life, and their shopping habits may experience a major change during that period. The retailing company wants to leverage this special opportunity.  \n"," \nAn insurer uses its facial-recognition technology mainly to verify customers identities. When people open accounts with the insurer, they are asked to submit images of their photo ids and complete a series of tasks including opening their mouths and blinking when they use the companys facial-recognition program for the first time.  \n"," \nThe company also use facial recognition technology in its insurance business to gauge customers health. For example, they can use facial scans to estimate the body-mass index (BMI) of customers who want to purchase a policy.  "," \nPolicyholders get discounts on their monthly premiums based on how much body fat they have, as calculated by the scan. Individuals judged to have a BMI under 30 can receive a 20% monthly discount on the product. A BMI of 30 or higher is considered obese.  \n"," \nA social networking service company provides a platform for its users to post their recent updates and share content. Peoples friends frequently produce much more content than one person can view, so the company develops a News Feed to filters posts, stories, and activities undertaken by friends. The platform records all the links users have visited, liked, commented, and shared.  \n"," \nThe company analyzes the content of each visited link and users' behavior, and then builds an interest profile for each user. For all the content a user's friends post and share, the company develops an algorithm that ranks these content in the interest of showing viewers the content they will find most relevant and engaging.  "," \nThe News Feed algorithm will hide the lower priority content and only show users the content they are more likely to engage. \n"," \nAn online travel agency offers an online booking service for flights and hotels. Users can search, select, and book through a website interface or mobile apps. Whenever a user visits the service, the company collects users data, such as operating system, browser type, as well as past purchases and clicks.  \n"," \nThe agency aggregates the past purchase behavior and finds that users using different devices\/browsers are willing to pay different amounts of money.  "," \nThe agency decides to incorporate the device-based price discrimination to their system. For example, users book a hotel room with iOS may receive a special unadvertised discount ($15 per night). Users who are visiting on Chrome or IE may be charged $50 more expensive on those browsers than on others. An automated algorithm determines the specific number.  \n"," \nA pregnancy-tracking app provides health-care aid for women to understand their bodies better. Users can log in to record their bodily function, e.g., sex drive, medications, and mood. The app has a \"fertility algorithms\", which analyze the user's menstrual data and suggest good times to try to conceive.\nYour company establishes a partnership with the app developer. Your employer pays each employee $1 a day in gift card if she regularly uses the app. \n"," \nThe pregnancy-tracking app aggregates the data of employees in the same company and removes personally identifiable information (e.g., name, email, age). "," \nThe employer pays the app developer to get their employees' aggregated health data, e.g., how many workers using the app had faced high-risk pregnancies or gave birth prematurely; the top medical questions they had researched; and how soon the new moms planned to return to work. \n"," \nThe employer plans to use that data to minimize health-care spending, discover medical problems and better plan human resources for the months ahead. \n"," \nA wearable technology company sells fitness and calorie trackers to users. The tracker can measure data such as the number of steps walked, heart rate, etc. Alongside the wearable tracker, the company offers a website and mobile apps, where users can log their food, activities, and weight manually.  \n"," \nThe company develops several algorithms to analyze the data collected from the tracker and predicts the types of metabolism activity - along with duration and intensity.  "," \nUsers can manually annotate or input their untracked\/unrecognized activities as well, e.g., running, biking, swimming or \"sexual activity\", so they can have a quantified view of how many calories they have burned in a given period of time.  "," \nThe company also offers a social feature to users, where everyone can share their progress pictures as well as their activities. When the user creates a social profile, the default privacy setting allows profiles to be found in search results (Google, Bing, etc.). If the user doesnt uncheck the setting, the users activities would be searchable in the public search engine.  \n"," \nA web search engine company wants to determine the shade of blue for web links. The company randomly use 40 different shades of blue to each 2.5% of visitors and records visitors' clickthrough behaviors. The company will not inform their users this change. The collected data are *not* anonymous. \n"," \nThe company analyzes each user's clickthrough data and finds that each user has her own color preference. Namely, each user is more likely to click an advertisement link if the link color is in a preferred color. "," \nThe search engine company shares users' color preference to a social network company. \n"," \nThe social network company later customizes the color of advertisement links based on the data from the search engine company. Users may click more advertisement unconsciously. \n"," \nA game company runs a large online real-time role-playing game community, which is being criticized for the toxic culture. The game company records all the users' in-game chatlogs to support further analysis. Meanwhile, the company also collects users' credit card number and other personally identifiable information (PII) through common interactions (e.g., in-game purchase, registration). \n"," \nThe company develops a sophisticated artificial intelligence algorithm to identify abusive language usages in the in-game chatlogs. The company then assigns an in-game reputation score to each user. "," \nIt has been proved that there exists a correlation between poor in-game reputation and problem behavior at work. Toxic players tended to be toxic employees. The company sells the data to several staffing agencies with personally identifiable information. \n"," \nThe staffing agencies use the in-game reputation score to rank and filter their job candidates. \n"," \nA technology company offers a peer-to-peer ride-sharing service through a mobile app. Users can use the app to request a ride service and see a real-time price estimate in advance. The company also collects users' phone information whenever users are using the app, such as device models, battery information (e.g., remaining battery level, whether the phone is charging). \n"," \nThe company aggregates the battery information from millions of users and finds that users are more likely to pay for a higher price if the battery is low on their phones. "," \nThe company decides to incorporate the battery-based price surging feature to the app. Namely, the will charge users with a low battery more than users with a high battery. \n"," \nYour favorite retail store offers you a free loyalty card. You can get a discounted price on some purchases when you present the card. To obtain the card, you are required to fill out a form with your name, address, and phone number, which may then be associated with a list of your purchases. \n"," \nThe retail store sells your data to a health insurance company. \n"," \nYour health insurance company analyzes your purchases and concludes you have a sedentary lifestyle and an unhealthy diet. "," \nThe insurance company then raises your insurance rates. \n"," \nAn online dating app studies the social interactions you share on its platform. The app collects detailed information about you, including demographic information and your behavioral data happened on its platform. Users agreement says that when you sign up for the site, personal data may be used in research and analysis. \n"," \nThe company runs an experiment called love is blind to understand the romantic relationship. On one day, the app takes off all profile photos for a while to see if you would engage in more meaningful conversations, exchange more contact details and respond to first messages more often - if the profile photos are not displayed. It reintroduces the pictures afterward. \n"," \nAn e-commerce company plans to open a checkout-free retail store. Customers can simply walk in, grab what they need, and go. To achieve that, each store will have cameras nestled in the ceiling to monitor customers' behavior and sensors on the shelves to monitor the item movement. \n"," \nThe company develops sophisticated artificial intelligence algorithms to analyze the video footages from the cameras and other sensor readings. These algorithms will use face recognition to identify users, continuously monitor users' movement, and track the items users put in their baskets. "," \nThe company plans to offer automated pricing, already used for things like airline tickets, in the local store. A store's AI might see you, a loyal customer, standing in front of the yogurt case or trying on winter coats and offer a 15 percent discount. Or it might charge you more because it knows you're in a rush and live in an affluent zip code. Prices may also fluctuate in real time based on demand, just like ridesharing. \n"," \nA social networking service company provides a platform for its users to post their recent updates and share content. Peoples friends frequently produce much more content than one person can view, so the company develops a News Feed to filters posts, stories, and activities undertaken by friends. The platform records all the links users have visited, liked, commented, and shared.  \n"," \nThe company analyzes the content of each visited link and users' behavior, and then builds an interest profile for each user. For all the content a user's friends post and share, the company develops an algorithm that ranks these content in the interest of showing viewers the content they will find most relevant and engaging.  "," \nThe News Feed algorithm will hide the lower priority content and only show users the content they are more likely to engage. \n"," \nA technology company provides multiple internet-related services to their users. In their email service, the company records users' sent\/received\/drafted emails on its server, as well as the names of their email contacts. \n"," \nAnother team in the company recently launches a new social network service. The email team shares users' email data (e.g., frequent contacts) with the social network team. \n"," \nWhen an email user enrolls the new social network service, the user will automatically follow everyone in his\/her email contact list. These contacts will have view access to the user's social network profile. The profile includes but not limited to the user's followers\/followees (i.e., other email contacts), profiles in other internet services, e.g., e-reading. The user can block a specific user in the setting page manually. \n"]

news=[
    "The article discusses the Target and Neiman Marcus data breaches, which affected millions of customers. The breaches involved the theft of credit and debit card information, as well as personally identifiable information such as names, addresses, email addresses, and telephone numbers. The hackers used malware to infiltrate the retailers' computer systems and steal the data. The article also provides information on how affected individuals can find out if they have been impacted and what steps they can take to protect themselves.",
    "Classified documents leaked by NSA whistleblower Edward Snowden revealed that popular smartphone apps were being used by British and American intelligence agencies to gather sensitive information about users, including their location, political affiliation, and even their sexual orientation. The agencies were exploiting poorly secured mobile apps to collect and decode data transmitted back to developers, allowing them to gather personal records for analysis. Additionally, GCHQ developed technology to spy on people en masse as they used social networks and other big-name websites, collecting data on user behavior based on their browser choice. Snowden also claimed that the NSA had hacked business systems, including those of German manufacturer Siemens, and had monitored German Chancellor Angela Merkel. ",
    "Hackers reportedly uploaded explicit images believed to have been sent through Snapchat, with threats to release more. The images were intercepted from users accessing the service via third-party apps, raising concerns about the privacy and safety of the app's predominantly young user base. While Snapchat denied a breach of its servers, security experts called for the company to take more responsibility for user data and address potential vulnerabilities. This incident adds to previous security and privacy concerns for Snapchat, including leaked usernames and phone numbers earlier in the year.",
    "A domestic Internet security monitoring platform has warned that tens of millions of China Telecom users are at risk of personal information leakage due to a system loophole. Hackers can easily exploit the loophole to access private user information, such as names, ID numbers, and bank balances, and even carry out actions like replenishing, closing accounts, or changing numbers. China Telecom has confirmed the existence of the loophole and may have taken steps to address it.",
    "A hacker has gained access to the records of 15 million T-Mobile customers and credit applicants through a breach at Experian, the vendor that processes T-Mobile's credit applications. The compromised information includes names, addresses, birth dates, and encrypted fields with Social Security numbers and ID numbers. Experian and T-Mobile are offering two years of free credit monitoring and identity resolution services for affected customers, but caution against providing personal information to anyone claiming to be associated with the breach.",
]